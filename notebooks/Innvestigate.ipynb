{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Y4wV366e5l",
        "outputId": "39884b86-d3e5-404d-8ffc-1f2c50337879"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7iBrIg9twYS"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install scikit-learn\n",
        "!pip install efficientnet\n",
        "!pip install innvestigate\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_eff\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/face_forensic'):\n",
        "  for filename in filenames:\n",
        "    print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "VxWZlhWE5FqA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "6hDzADO0y4zU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faceforensis_real_path = \"/content/drive/MyDrive/face_forensic/REAL\"\n",
        "faceforensis_fake_deepfake = \"/content/drive/MyDrive/face_forensic/Deepfake\"\n",
        "faceforensis_fake_deepfakedetection = \"/content/drive/MyDrive/face_forensic/DeepfakeDetection\"\n",
        "faceforensis_fake_face2face = \"/content/drive/MyDrive/face_forensic/Face2Face\"\n",
        "faceforensis_fake_faceshifter = \"/content/drive/MyDrive/face_forensic/FaceShifter\"\n",
        "faceforensis_fake_faceswap = \"/content/drive/MyDrive/face_forensic/FaceSwap\"\n",
        "faceforensis_fake_neuraltextures = \"/content/drive/MyDrive/face_forensic/NeuralTextures\"\n",
        "\n",
        "# models\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "eff_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "PibiXRqn73tF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def listar_arquivos(pasta):\n",
        "    if not os.path.exists(pasta):\n",
        "        print(f\"[ERRO] Pasta não encontrada: {pasta}\")\n",
        "        return\n",
        "\n",
        "    arquivos = os.listdir(pasta)\n",
        "    print(f\"Total de arquivos em {pasta}: {len(arquivos)}\")\n",
        "    print(\"Exemplo de arquivos:\", arquivos[:5])\n",
        "\n",
        "listar_arquivos(faceforensis_real_path)\n",
        "listar_arquivos(faceforensis_fake_deepfake)\n"
      ],
      "metadata": {
        "id": "y9svYNWEIOJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import innvestigate.utils.visualizations as ivis\n",
        "\n",
        "channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
        "color_conversion = \"BGRtoRGB\"\n",
        "\n",
        "def postprocess(X, color_conversion, channels_first):\n",
        "  X = X.copy()\n",
        "  X = iutils.postprocess_images(\n",
        "      X, color_coding=color_conversion, channels_first=channels_first\n",
        "  )\n",
        "  return X\n",
        "\n",
        "def heatmap(X):\n",
        "  return ivis.heatmap(X)"
      ],
      "metadata": {
        "id": "xKGHDVYH761-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"REAL\", \"FAKE\"])\n",
        "  plt.figure(figsize=(5, 5))\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BgrDk9GZ8h2E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_from_image(image_path):\n",
        "  if not os.path.isfile(image_path):\n",
        "    print(f\"[ERRO] O arquivo {image_path} não é válido ou não é uma imagem.\")\n",
        "    return None\n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "  if img is None:\n",
        "    print(f\"[ERRO] Não foi possível carregar a imagem {image_path}.\")\n",
        "    return None\n",
        "\n",
        "  img_resized = cv2.resize(img, (224, 224))\n",
        "  img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  img_batch_vgg = preprocess_vgg(np.expand_dims(img_rgb.astype('float32'), axis = 0))\n",
        "  img_batch_resnet = preprocess_resnet(np.expand_dims(img_rgb.astype('float32'), axis=0))\n",
        "  img_batch_eff = preprocess_eff(np.expand_dims(img_rgb.astype('float32'), axis=0))\n",
        "\n",
        "  vgg_feat = vgg_model.predict(img_batch_vgg, verbose=0).flatten()\n",
        "  res_feat = resnet_model.predict(img_batch_resnet, verbose=0).flatten()\n",
        "  eff_feat = eff_model.predict(img_batch_eff, verbose=0).flatten()\n",
        "\n",
        "  combined = np.concatenate([vgg_feat, res_feat, eff_feat])\n",
        "\n",
        "  return combined\n",
        "\n",
        "def generate_model(real_path, fake_path):\n",
        "  X_train, y_train = [], []\n",
        "  X_test, y_test = [], []\n",
        "\n",
        "  for label, path in [(\"REAL\", real_path), (\"FAKE\", fake_path)]:\n",
        "    image_files = os.listdir(path)\n",
        "    test_files = image_files[:50]\n",
        "    train_files = image_files[50:]\n",
        "\n",
        "    for image_name in tqdm(test_files, desc=f\"{label} (TESTE)\"):\n",
        "      image_path = os.path.join(path, image_name)\n",
        "      feat = extract_features_from_image(image_path)\n",
        "      if feat is not None:\n",
        "        X_test.append(feat)\n",
        "        y_test.append(0 if label == \"REAL\" else 1)\n",
        "      else:\n",
        "        print(f\"[INFO] Não foram extraídas características de {image_path}\")\n",
        "\n",
        "    for image_name in tqdm(train_files, desc=f\"{label} (TREINO)\"):\n",
        "      image_path = os.path.join(path, image_name)\n",
        "      feat = extract_features_from_image(image_path)\n",
        "      if feat is not None:\n",
        "        X_train.append(feat)\n",
        "        y_train.append(0 if label == \"REAL\" else 1)\n",
        "      else:\n",
        "        print(f\"[INFO] Naõ foram extraídas características de {image_path}\")\n",
        "\n",
        "  if len(X_train) == 0 or len(X_test) == 0:\n",
        "    print(\"Erro: Não foram extraídas características suficientes para o treino ou teste.\")\n",
        "    return None, None\n",
        "\n",
        "  X_train = np.array(X_train)\n",
        "  y_train = np.array(y_train)\n",
        "  X_test = np.array(X_test)\n",
        "  y_test = np.array(y_test)\n",
        "\n",
        "  # PCA + SVM\n",
        "  pca = PCA(n_components=1)\n",
        "  X_train_pca = pca.fit_transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  svm = SVC(kernel='linear')\n",
        "  svm.fit(X_train_pca, y_train)\n",
        "\n",
        "  y_pred = svm.predict(X_test_pca)\n",
        "\n",
        "  print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"F1-score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "  if hasattr(svm, \"decision_function\"):\n",
        "    y_scores = svm.decision_function(X_test_pca)\n",
        "    auc = roc_auc_score(y_test, y_scores)\n",
        "    print(\"AUC:\", auc)\n",
        "  else:\n",
        "    print(\"O modelo SVM não possui decision_function para calcular a AUC.\")\n",
        "\n",
        "  print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "  return svm, pca\n",
        "\n"
      ],
      "metadata": {
        "id": "o-BR24V083Qp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chamada da função\n",
        "print(\"Deepfake\")\n",
        "svm_deepfake, pca_deepfake = generate_model(faceforensis_real_path, faceforensis_fake_deepfake)\n",
        "print(\"DeepfakeDetection\")\n",
        "svm_deepfakedetection, pca_deepfakedetection = generate_model(faceforensis_real_path, faceforensis_fake_deepfakedetection)\n",
        "print(\"Face2Face\")\n",
        "svm_face2face, pca_face2face = generate_model(faceforensis_real_path, faceforensis_fake_face2face)\n",
        "print(\"FaceShifter\")\n",
        "svm_faceshifter, pca_faceshifter = generate_model(faceforensis_real_path, faceforensis_fake_faceshifter)\n",
        "print(\"FaceSwap\")\n",
        "svm_faceswap, pca_faceswap = generate_model(faceforensis_real_path, faceforensis_fake_faceswap)\n",
        "print(\"NeuralTextures\")\n",
        "svm_neuratextures, pca_neuratextures = generate_model(faceforensis_real_path, faceforensis_fake_neuraltextures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJlBjntoET9s",
        "outputId": "f114b051-2f3c-4d20-cef2-53a3d8b2a783"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deepfake\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:50<00:00,  1.02s/it]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:46<00:00,  1.20it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:45<00:00,  1.09it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.41\n",
            "F1-score (macro): 0.40946852166950254\n",
            "AUC: 0.4\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.44      0.43        50\n",
            "           1       0.40      0.38      0.39        50\n",
            "\n",
            "    accuracy                           0.41       100\n",
            "   macro avg       0.41      0.41      0.41       100\n",
            "weighted avg       0.41      0.41      0.41       100\n",
            "\n",
            "DeepfakeDetection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:43<00:00,  1.16it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79\n",
            "F1-score (macro): 0.7874278773155178\n",
            "AUC: 0.9368000000000001\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81        50\n",
            "           1       0.87      0.68      0.76        50\n",
            "\n",
            "    accuracy                           0.79       100\n",
            "   macro avg       0.80      0.79      0.79       100\n",
            "weighted avg       0.80      0.79      0.79       100\n",
            "\n",
            "Face2Face\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:42<00:00,  1.19it/s]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:43<00:00,  1.15it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:46<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.35\n",
            "F1-score (macro): 0.34941447302572315\n",
            "AUC: 0.32520000000000004\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.38      0.37        50\n",
            "           1       0.34      0.32      0.33        50\n",
            "\n",
            "    accuracy                           0.35       100\n",
            "   macro avg       0.35      0.35      0.35       100\n",
            "weighted avg       0.35      0.35      0.35       100\n",
            "\n",
            "FaceShifter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:41<00:00,  1.20it/s]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:43<00:00,  1.15it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:47<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "F1-score (macro): 0.4832575444398512\n",
            "AUC: 0.4472\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.68      0.58        50\n",
            "           1       0.50      0.32      0.39        50\n",
            "\n",
            "    accuracy                           0.50       100\n",
            "   macro avg       0.50      0.50      0.48       100\n",
            "weighted avg       0.50      0.50      0.48       100\n",
            "\n",
            "FaceSwap\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:42<00:00,  1.18it/s]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:47<00:00,  1.19it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n",
            "F1-score (macro): 0.375\n",
            "AUC: 0.4508\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.20      0.25        50\n",
            "           1       0.43      0.60      0.50        50\n",
            "\n",
            "    accuracy                           0.40       100\n",
            "   macro avg       0.38      0.40      0.38       100\n",
            "weighted avg       0.38      0.40      0.38       100\n",
            "\n",
            "NeuralTextures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL (TESTE): 100%|██████████| 50/50 [00:41<00:00,  1.19it/s]\n",
            "REAL (TREINO): 100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n",
            "FAKE (TESTE): 100%|██████████| 50/50 [00:44<00:00,  1.13it/s]\n",
            "FAKE (TREINO): 100%|██████████| 200/200 [02:45<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.41\n",
            "F1-score (macro): 0.40946852166950254\n",
            "AUC: 0.37600000000000006\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.44      0.43        50\n",
            "           1       0.40      0.38      0.39        50\n",
            "\n",
            "    accuracy                           0.41       100\n",
            "   macro avg       0.41      0.41      0.41       100\n",
            "weighted avg       0.41      0.41      0.41       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}